{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFQ_Example_MetaLearning_QAOA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2azAL4KJk-T",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Quantum Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UFpHoRvJmwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BswWgdtnmSP",
        "colab_type": "text"
      },
      "source": [
        "# Meta-Learning for QAOA\n",
        "*Written by Michael Broughton, Antonio J. Martinez, and Guillaume Verdon*\n",
        "\n",
        "In this notebook you will explore the application of meta-learning techniques from [here](https://arxiv.org/abs/1907.05415) to improve initialization of QAOA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH1spy1rJ2ko",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/quantum/blob/research/metalearning_qaoa/metalearning_qaoa.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrWw_xv4fs44",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqx89K2caCR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33bc5ce2-44e9-4ba9-8c17-f3bc737b4605"
      },
      "source": [
        "!pip install --upgrade cirq==0.7.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cirq==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/29/a66c4c28306dae359745e37c4c10120e477da44cb050d06d8ceb1117a22a/cirq-0.7.0-py3-none-any.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.16 in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers~=2.0 in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (2.1.0)\n",
            "Collecting networkx==2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-api-python-client~=1.6 in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (1.7.11)\n",
            "Collecting protobuf==3.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib~=3.0 in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (3.1.3)\n",
            "Requirement already satisfied, skipping upgrade: requests~=2.18 in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (2.21.0)\n",
            "Collecting sympy==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/21/f4105795ca7f35c541d82c5b06be684dd2f5cb4f508fb487cd7aea4de776/sympy-1.4-py2.py3-none-any.whl (5.3MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3MB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from cirq==0.7.0) (3.6.6)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->cirq==0.7.0) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->cirq==0.7.0) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.3->cirq==0.7.0) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client~=1.6->cirq==0.7.0) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client~=1.6->cirq==0.7.0) (0.0.3)\n",
            "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client~=1.6->cirq==0.7.0) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client~=1.6->cirq==0.7.0) (0.11.3)\n",
            "Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client~=1.6->cirq==0.7.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.8.0->cirq==0.7.0) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq==0.7.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq==0.7.0) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib~=3.0->cirq==0.7.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq==0.7.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq==0.7.0) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq==0.7.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.18->cirq==0.7.0) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy==1.4->cirq==0.7.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client~=1.6->cirq==0.7.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client~=1.6->cirq==0.7.0) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client~=1.6->cirq==0.7.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.4.1->google-api-python-client~=1.6->cirq==0.7.0) (0.4.8)\n",
            "Building wheels for collected packages: networkx\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=e425c19a37b1cbcb46e04fab17948ce271d20113fb80c9969ce57b0f73204017\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
            "Successfully built networkx\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: networkx, protobuf, sympy, cirq\n",
            "  Found existing installation: networkx 2.4\n",
            "    Uninstalling networkx-2.4:\n",
            "      Successfully uninstalled networkx-2.4\n",
            "  Found existing installation: protobuf 3.10.0\n",
            "    Uninstalling protobuf-3.10.0:\n",
            "      Successfully uninstalled protobuf-3.10.0\n",
            "  Found existing installation: sympy 1.1.1\n",
            "    Uninstalling sympy-1.1.1:\n",
            "      Successfully uninstalled sympy-1.1.1\n",
            "Successfully installed cirq-0.7.0 networkx-2.3 protobuf-3.8.0 sympy-1.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuXxC5fbaGAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "41b0c422-7316-4b7d-8183-a033b7c1b743"
      },
      "source": [
        "!pip install --upgrade tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |██████████████████████████      | 343.8MB 1.3MB/s eta 0:01:03"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyrqkto1aHQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tfq-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW2sb1rAfhwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cirq\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "import sympy\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "np.random.seed(123)\n",
        "random.seed(123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0rC9eTXqPaR",
        "colab_type": "text"
      },
      "source": [
        "## QAOA\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JywerwWEqsqY",
        "colab_type": "text"
      },
      "source": [
        "The QAOA ansatz consists of repeated applications of a mixer Hamiltonian $\\hat{H}_M$ and the cost Hamiltonian $\\hat{H}_C$.  The total applied unitary is\n",
        "$$\\hat{U}(\\eta,\\gamma) = \\prod_{j=1}^{p}e^{-i\\eta_{j}\\hat{H}_M}e^{-i\\gamma_{j} \\hat{H}_C},$$\n",
        "where $p$ is the number of timesthe mixer and cost are applied; the parameters $\\eta_j, \\gamma_j$ are to be optimized to produce a bitstring of minimal energy with respect to $\\hat{H}_C$.\n",
        "\n",
        "One traditional family of Hamiltonians used in QAOA are the Ising models.  These are defined as\n",
        "$$\\hat{H}_\\mathrm{P}=\\sum_i h_i \\hat{Z}^{(i)}+\\sum_{i,j} J_{ij} \\hat{Z}^{(i)}\\hat{Z}^{(j)}.$$\n",
        "There is a one-to-one mapping between weighted graphs and Ising models: $h_i$ can be thought of as the weight of a graph node $i$ and $J_{ij}$ can be thought of as the weight of a graph edge between nodes $i$ and $j$.  In applications such as [MaxCut](https://en.wikipedia.org/wiki/Maximum_cut), we have $h_i = 0$ and $J_{ij} = 1 \\forall i, j$.  We this define a function that takes a graph and outputs the corresponding Ising model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsYSfSCrqVMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxcut_qaoa_from_graph(graph, p):\n",
        "  qubits = cirq.GridQubit.rect(1, len(graph.nodes))\n",
        "  qaoa_circuit = cirq.Circuit()\n",
        "  # Initial equal superposition\n",
        "  for qubit in qubits:\n",
        "    qaoa_circuit += cirq.H(qubit)\n",
        "  qaoa_symbols = []\n",
        "  # Stack the parameterized costs and mixers\n",
        "  for l_num in range(p):\n",
        "    qaoa_symbols.append(sympy.Symbol(\"gamma_{}\".format(l_num)))\n",
        "    for e in graph.edges():\n",
        "      qaoa_circuit += cirq.ZZ(qubits[e[0]], qubits[e[1]])**qaoa_symbols[-1]\n",
        "    qaoa_symbols.append(sympy.Symbol(\"eta_{}\".format(l_num)))\n",
        "    for n in graph.nodes():\n",
        "      qaoa_circuit += cirq.X(qubits[n])**qaoa_symbols[-1]\n",
        "  # Define the cost as a Cirq PauliSum\n",
        "  cost_op = None\n",
        "  for e in graph.edges():\n",
        "    if cost_op is None:\n",
        "      cost_op = cirq.Z(qubits[e[0]])*cirq.Z(qubits[e[1]])\n",
        "    else:\n",
        "      cost_op += cirq.Z(qubits[e[0]])*cirq.Z(qubits[e[1]])\n",
        "  return qaoa_circuit, qaoa_symbols, cost_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qsBNoLYr3M4",
        "colab_type": "text"
      },
      "source": [
        "## Meta-Learning for MaxCut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbUFDaCtgc78",
        "colab_type": "text"
      },
      "source": [
        "The idea of meta-learning for optimization is to train an outer-loop optimizer on many instances of a problem class, to enhance the efficiency of solving unseen instances.  In other words, the learner is attempting to extract the common structure among instances of a particular class of problems.\n",
        "\n",
        "Here, you will use a recurrent neural network to find good initial parameter settings for MaxCut QAOA instances.  As shown in the [original paper](https://arxiv.org/abs/1907.05415), this is an effective method for overcoming the challenge of [\"barren plateaus\"](https://www.nature.com/articles/s41467-018-07090-4) in quantum machine learning.\n",
        "\n",
        "To this end we define a function that generates a set of random MaxCut QAOA instances, based on graphs sampled from an [Erdős–Rényi](https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model) distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2iWPCuIf1DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(n_nodes, n_points):\n",
        "  datapoints = []\n",
        "  costs = []\n",
        "  for _ in range(n_points):\n",
        "    random_graph = nx.gnp_random_graph(n_nodes, p=3. / n_nodes)\n",
        "    circuit, symbols, cost_op = maxcut_qaoa_from_graph(random_graph, 1)\n",
        "    datapoints.append(circuit)\n",
        "    costs.append([cost_op])\n",
        "  return datapoints, symbols, costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqp69jRYgqUy",
        "colab_type": "text"
      },
      "source": [
        "Since our recurrent neural network will have both classical and quantum components, we will need to define a custom RNN layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ufim5zxtK5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QRNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, symbol_names):\n",
        "    super(QRNN, self).__init__()\n",
        "    self.shared = tf.keras.layers.Dense(25, name=\"shared\")\n",
        "    self.state = tf.keras.layers.Dense(25, name=\"state\")\n",
        "    self.params = tf.keras.layers.Dense(2, name=\"params\")\n",
        "    self.expectation = tfq.layers.Expectation()\n",
        "    self.symbol_names = symbol_names\n",
        "\n",
        "  def call(self, inputs):\n",
        "    circuits = inputs[0]\n",
        "    ops = inputs[1]\n",
        "    state = inputs[2]\n",
        "    params = inputs[3]\n",
        "    prev_output = inputs[3]\n",
        "    joined = tf.keras.layers.concatenate([state, params, prev_output])\n",
        "    shared = self.shared(joined)\n",
        "    s_inp = self.state(shared)\n",
        "    p_inp = self.params(shared)\n",
        "    exp_out = self.expectation(circuits,\n",
        "                               symbol_names=self.symbol_names,\n",
        "                               symbol_values=p_inp,\n",
        "                               operators=ops)\n",
        "    return [circuits, ops, s_inp, p_inp, exp_out]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4XJuhHfw8ZA",
        "colab_type": "text"
      },
      "source": [
        "This layer is stacked to produce the meta-learner RNN.  We choose 5 shots of optimization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPL-CRJUgj_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate random MaxCut instances as training data.\n",
        "N_QUBITS = 10\n",
        "\n",
        "# For a more accurate optimizer on testing data, increase N_POINTS\n",
        "N_POINTS = 500\n",
        "circuits, symbols, ops = generate_data(N_QUBITS, N_POINTS)\n",
        "circuit_tensor = tfq.convert_to_tensor(circuits)\n",
        "ops_tensor = tfq.convert_to_tensor(ops)\n",
        "\n",
        "# Unroll the RNN through time.\n",
        "state_inp = tf.keras.Input(shape=(25,))\n",
        "params_inp = tf.keras.Input(shape=(2,))\n",
        "exp_inp = tf.keras.Input(shape=(25,))\n",
        "\n",
        "op_inp = tf.keras.Input(shape=(1,), dtype=tf.dtypes.string)\n",
        "circuit_inp = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
        "\n",
        "rnn_0 = QRNN(symbols)\n",
        "rnn_1 = QRNN(symbols)\n",
        "rnn_2 = QRNN(symbols)\n",
        "rnn_3 = QRNN(symbols)\n",
        "rnn_4 = QRNN(symbols)\n",
        "output_0 = rnn_0([circuit_inp, op_inp, state_inp, params_inp, exp_inp])\n",
        "output_1 = rnn_1(output_0)\n",
        "output_2 = rnn_2(output_1)\n",
        "output_3 = rnn_3(output_2)\n",
        "output_4 = rnn_4(output_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCmvJEUrGsXs",
        "colab_type": "text"
      },
      "source": [
        "Now we can set up a loss function over the 5 timesteps of our RNN QAOA optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Fp2eOYzsAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def value_loss(unused, outputs):\n",
        "    return tf.reduce_mean(outputs)\n",
        "\n",
        "# It's important to have a good guess on the last shot of the optimization\n",
        "loss = tf.keras.layers.average([\n",
        "    0.1 * output_0[4], 0.2 * output_1[4], 0.3 * output_2[4],\n",
        "    0.4 * output_3[4], 0.5 * output_4[4]\n",
        "])\n",
        "\n",
        "# Penalize jumping around randomly in the landscape.\n",
        "penalizer = 10 * tf.reduce_sum(\n",
        "    (output_0[3] - output_1[3])**2 + (output_1[3] - output_2[3])**2 +\n",
        "    (output_2[3] - output_3[3])**2 + (output_3[3] - output_4[3])**2,\n",
        "    axis=1)\n",
        "full_loss = loss + penalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM-UGe11UPXp",
        "colab_type": "text"
      },
      "source": [
        "Finally we set and train our full Keras model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sykuyNseURcC",
        "colab_type": "code",
        "outputId": "a2a13a04-c69f-413a-8928-f72cc9727dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Can change these to random along with longer tine horizon and greater training\n",
        "# data for more robust test set performance\n",
        "initial_state = np.zeros((N_POINTS, 25)).astype(np.float32)\n",
        "initial_params = np.zeros((N_POINTS, 2)).astype(np.float32)\n",
        "initial_exp = np.zeros((N_POINTS, 25)).astype(np.float32)\n",
        "\n",
        "# Our model will output it's parameter guesses along with the loss value that is\n",
        "# computed over them. This way we can use the model to guess parameters later on\n",
        "model = tf.keras.Model(inputs=[state_inp, params_inp, exp_inp, op_inp, circuit_inp],\n",
        "    outputs=[\n",
        "        output_0[3], output_1[3], output_2[3], output_3[3], output_4[3],\n",
        "        full_loss\n",
        "    ])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=value_loss, loss_weights=[0, 0, 0, 0, 0, 1])\n",
        "\n",
        "model.fit(x=[initial_state, initial_params, initial_exp, ops_tensor, circuit_tensor],\n",
        "          y=[\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1)),\n",
        "              np.zeros((N_POINTS, 1))\n",
        "          ],\n",
        "          epochs=20,\n",
        "          batch_size=64,\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 500 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['qrnn_4/state/kernel:0', 'qrnn_4/state/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['qrnn_4/state/kernel:0', 'qrnn_4/state/bias:0'] when minimizing the loss.\n",
            "500/500 [==============================] - 9s 18ms/sample - loss: -0.0027 - qrnn_loss: -2.8565e-04 - qrnn_1_loss: -4.5328e-04 - qrnn_2_loss: -5.3460e-04 - qrnn_3_loss: 8.9863e-05 - qrnn_4_loss: 7.5090e-04 - tf_op_layer_add_3_loss: -0.0028\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.0311 - qrnn_loss: -0.0015 - qrnn_1_loss: -0.0014 - qrnn_2_loss: -0.0017 - qrnn_3_loss: 1.9811e-04 - qrnn_4_loss: 0.0022 - tf_op_layer_add_3_loss: -0.0317\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.1145 - qrnn_loss: -0.0028 - qrnn_1_loss: -0.0030 - qrnn_2_loss: -0.0033 - qrnn_3_loss: 3.4117e-04 - qrnn_4_loss: 0.0045 - tf_op_layer_add_3_loss: -0.1160\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.2601 - qrnn_loss: -0.0035 - qrnn_1_loss: -0.0047 - qrnn_2_loss: -0.0047 - qrnn_3_loss: 0.0020 - qrnn_4_loss: 0.0076 - tf_op_layer_add_3_loss: -0.2619\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.4265 - qrnn_loss: -0.0033 - qrnn_1_loss: -0.0061 - qrnn_2_loss: -0.0045 - qrnn_3_loss: 0.0052 - qrnn_4_loss: 0.0097 - tf_op_layer_add_3_loss: -0.4284\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.5490 - qrnn_loss: -0.0024 - qrnn_1_loss: -0.0063 - qrnn_2_loss: -8.3205e-04 - qrnn_3_loss: 0.0103 - qrnn_4_loss: 0.0125 - tf_op_layer_add_3_loss: -0.5495\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 5s 10ms/sample - loss: -0.6239 - qrnn_loss: -0.0012 - qrnn_1_loss: -0.0050 - qrnn_2_loss: 0.0048 - qrnn_3_loss: 0.0155 - qrnn_4_loss: 0.0165 - tf_op_layer_add_3_loss: -0.6246\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.6823 - qrnn_loss: 1.9863e-04 - qrnn_1_loss: -0.0023 - qrnn_2_loss: 0.0089 - qrnn_3_loss: 0.0174 - qrnn_4_loss: 0.0170 - tf_op_layer_add_3_loss: -0.6829\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.7276 - qrnn_loss: 0.0019 - qrnn_1_loss: 7.7907e-04 - qrnn_2_loss: 0.0101 - qrnn_3_loss: 0.0166 - qrnn_4_loss: 0.0176 - tf_op_layer_add_3_loss: -0.7288\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.7671 - qrnn_loss: 0.0035 - qrnn_1_loss: 0.0031 - qrnn_2_loss: 0.0085 - qrnn_3_loss: 0.0139 - qrnn_4_loss: 0.0157 - tf_op_layer_add_3_loss: -0.7674\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.8006 - qrnn_loss: 0.0047 - qrnn_1_loss: 0.0044 - qrnn_2_loss: 0.0080 - qrnn_3_loss: 0.0133 - qrnn_4_loss: 0.0157 - tf_op_layer_add_3_loss: -0.8013\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.8294 - qrnn_loss: 0.0054 - qrnn_1_loss: 0.0052 - qrnn_2_loss: 0.0093 - qrnn_3_loss: 0.0146 - qrnn_4_loss: 0.0162 - tf_op_layer_add_3_loss: -0.8293\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.8542 - qrnn_loss: 0.0057 - qrnn_1_loss: 0.0059 - qrnn_2_loss: 0.0109 - qrnn_3_loss: 0.0149 - qrnn_4_loss: 0.0165 - tf_op_layer_add_3_loss: -0.8545\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 5s 10ms/sample - loss: -0.8765 - qrnn_loss: 0.0056 - qrnn_1_loss: 0.0070 - qrnn_2_loss: 0.0112 - qrnn_3_loss: 0.0152 - qrnn_4_loss: 0.0167 - tf_op_layer_add_3_loss: -0.8764\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.8973 - qrnn_loss: 0.0053 - qrnn_1_loss: 0.0080 - qrnn_2_loss: 0.0116 - qrnn_3_loss: 0.0151 - qrnn_4_loss: 0.0167 - tf_op_layer_add_3_loss: -0.8969\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.9172 - qrnn_loss: 0.0049 - qrnn_1_loss: 0.0085 - qrnn_2_loss: 0.0121 - qrnn_3_loss: 0.0154 - qrnn_4_loss: 0.0169 - tf_op_layer_add_3_loss: -0.9177\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.9365 - qrnn_loss: 0.0044 - qrnn_1_loss: 0.0086 - qrnn_2_loss: 0.0125 - qrnn_3_loss: 0.0156 - qrnn_4_loss: 0.0169 - tf_op_layer_add_3_loss: -0.9363\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.9553 - qrnn_loss: 0.0039 - qrnn_1_loss: 0.0085 - qrnn_2_loss: 0.0126 - qrnn_3_loss: 0.0158 - qrnn_4_loss: 0.0170 - tf_op_layer_add_3_loss: -0.9550\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 5s 9ms/sample - loss: -0.9736 - qrnn_loss: 0.0035 - qrnn_1_loss: 0.0083 - qrnn_2_loss: 0.0124 - qrnn_3_loss: 0.0154 - qrnn_4_loss: 0.0169 - tf_op_layer_add_3_loss: -0.9740\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 5s 10ms/sample - loss: -0.9914 - qrnn_loss: 0.0031 - qrnn_1_loss: 0.0081 - qrnn_2_loss: 0.0124 - qrnn_3_loss: 0.0156 - qrnn_4_loss: 0.0167 - tf_op_layer_add_3_loss: -0.9921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe593a8a048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYxwwKM3g4vL",
        "colab_type": "text"
      },
      "source": [
        "(Doing validation data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptNh_hPig1zk",
        "colab_type": "code",
        "outputId": "c17b1b58-a4f1-464d-9829-d5c1f5fe4ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "circuits, parameters, ops = generate_data(10, N_POINTS // 2)\n",
        "\n",
        "circuit_tensor = tfq.convert_to_tensor(circuits)\n",
        "ops_tensor = tfq.convert_to_tensor(ops)\n",
        "\n",
        "initial_state = np.zeros((N_POINTS // 2, 25)).astype(np.float32)\n",
        "initial_guesses = np.zeros((N_POINTS // 2, 2)).astype(np.float32)\n",
        "initial_exp = np.zeros((N_POINTS // 2, 25)).astype(np.float32)\n",
        "\n",
        "out1, out2, out3, out4, out5, _ = model(\n",
        "    [initial_state, initial_guesses, initial_exp, ops_tensor, circuit_tensor])\n",
        "\n",
        "one_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out1,\n",
        "    operators=ops_tensor)).numpy()\n",
        "two_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out2,\n",
        "    operators=ops_tensor)).numpy()\n",
        "three_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out3,\n",
        "    operators=ops_tensor)).numpy()\n",
        "four_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out4,\n",
        "    operators=ops_tensor)).numpy()\n",
        "five_vals = tf.reduce_mean(tfq.layers.Expectation()(\n",
        "    circuit_tensor,\n",
        "    symbol_names=parameters,\n",
        "    symbol_values=out5,\n",
        "    operators=ops_tensor)).numpy()\n",
        "\n",
        "average_cost_function_values = [\n",
        "    one_vals, two_vals, three_vals, four_vals, five_vals\n",
        "]\n",
        "std_of_param_guess = [\n",
        "    tf.math.reduce_std(out1).numpy(),\n",
        "    tf.math.reduce_std(out2).numpy(),\n",
        "    tf.math.reduce_std(out3).numpy(),\n",
        "    tf.math.reduce_std(out4).numpy(),\n",
        "    tf.math.reduce_std(out5).numpy()\n",
        "]\n",
        "\n",
        "print('-' * 80)\n",
        "print('Average cost function values for each guess number across unseen instances:',\n",
        "      average_cost_function_values)\n",
        "print('Variance of parameter values guessed:', std_of_param_guess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Average cost function values for each guess number across unseen instances: [-0.93607825, -3.0742426, -4.011084, -4.235294, -4.2729025]\n",
            "Variance of parameter values guessed: [0.06207718, 0.13089399, 0.17260134, 0.19353636, 0.20162843]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvs5E__KhEHu",
        "colab_type": "text"
      },
      "source": [
        "Explore a singular instances. Now this instance is on 12 qubits and not just 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWMazq46hBB6",
        "colab_type": "code",
        "outputId": "cf3eb795-04e1-4507-d18b-6b7a229db4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "test_graph_circuit, parameters, test_graph_op = generate_data(12, 1)\n",
        "\n",
        "test_graph_circuit = test_graph_circuit[0]\n",
        "test_graph_op = test_graph_op[0][0]\n",
        "\n",
        "resolution = 100\n",
        "input_vals = []\n",
        "for i, a in enumerate(np.linspace(-0.5, .5, resolution)):\n",
        "    for j, b in enumerate(np.linspace(-0.5, .5, resolution)):\n",
        "        input_vals.append([a, b])\n",
        "\n",
        "cost_vals = tfq.layers.Expectation()(test_graph_circuit,\n",
        "                                     symbol_names=parameters,\n",
        "                                     symbol_values=np.array(input_vals),\n",
        "                                     operators=test_graph_op).numpy()\n",
        "\n",
        "output_vals = np.empty((resolution, resolution))\n",
        "for i, a in enumerate(np.linspace(-0.5, 0.5, resolution)):\n",
        "    for j, b in enumerate(np.linspace(-0.5, 0.5, resolution)):\n",
        "        output_vals[i][j] = cost_vals[i * resolution + j]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(output_vals)\n",
        "\n",
        "guess_0, guess_1, guess_2, guess_3, guess_4, _ = model([\n",
        "    np.zeros((1, 25)).astype(np.float32),\n",
        "    np.zeros((1, 2)).astype(np.float32),\n",
        "    np.zeros((1, 25)).astype(np.float32),\n",
        "    tfq.convert_to_tensor([[test_graph_op]]),\n",
        "    tfq.convert_to_tensor([test_graph_circuit]),    \n",
        "])\n",
        "all_guesses = [guess_0, guess_1, guess_2, guess_3, guess_4]\n",
        "all_guesses = [list(a.numpy()[0]) for a in all_guesses]\n",
        "\n",
        "\n",
        "# This should be cleaned up...\n",
        "def f(x):\n",
        "    sim = cirq.Simulator()\n",
        "    final_state = sim.simulate(test_graph_circuit, {\n",
        "        parameters[0]: x[0],\n",
        "        parameters[1]: x[1]\n",
        "    }).final_state\n",
        "    q = sorted(list(test_graph_circuit.all_qubits()))\n",
        "    res = test_graph_op.expectation_from_wavefunction(\n",
        "        final_state, qubit_map={h: i for i, h in enumerate(q)}).real\n",
        "    return res\n",
        "\n",
        "\n",
        "all_costs = [f(a) for a in all_guesses]\n",
        "\n",
        "plt.plot((np.array(all_guesses)[:, 0] + 0.5) * resolution,\n",
        "         (np.array(all_guesses)[:, 1] + 0.5) * resolution,\n",
        "         c='r',\n",
        "         linestyle='--',\n",
        "         markevery=[4],\n",
        "         marker='*',\n",
        "         markersize=20,\n",
        "         linewidth=3.5)\n",
        "plt.show()\n",
        "\n",
        "print('All guesses for test graph:', all_guesses)\n",
        "print('Cost function values for test graph:', all_costs)\n",
        "print('-' * 80)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "All guesses for test graph: [[-0.05920046, 0.06495389], [-0.12289892, 0.138889], [-0.1600413, 0.18516134], [-0.17817873, 0.20889395], [-0.18445928, 0.21879752]]\n",
            "Cost function values for test graph: [-1.2702649869024754, -3.7216290906071663, -4.45371687412262, -4.50318269431591, -4.4711898267269135]\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__ae8ksZdTkb",
        "colab_type": "text"
      },
      "source": [
        "As we can see from the above visual the RNN immediately begins guessing near the basin of attraction and continues to explore around the region looking to improve the estimate. Note the values in `all_costs` decreasing."
      ]
    }
  ]
}